<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>R and PostgreSQL</title>
    <meta charset="utf-8" />
    <meta name="author" content="Sebastian Hoyos-Torres" />
    <meta name="date" content="2019-11-06" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# R and PostgreSQL
### Sebastian Hoyos-Torres
### CUNY Graduate Center and Caret Lab
### 2019-11-06

---

&lt;style&gt;

.center2 {
position: absolute;
top: 45%;
left: 25%;
right: 50%; 
width: 50%;
}

&lt;/style&gt;


--- 
# Welcome

- Reasons you may be interested in this presentation:

--
  - You like R
  - You are curious about postgreSQL
  - You might want to use both and are interested in best practices to integrate them

--
- Reasons to stay if these aren't appealing

--
.center2[
![](https://media.giphy.com/media/THrYOidLs0z9WCOvGi/giphy.gif)
]
---
# Why can't we do everything in R?

--
- R is great and I'm actually a massive fan if you don't already know.

--

- "Big Data" might overwhelm R though even after using all different tools

--

&gt; "If your data is bigger than this, carefully consider if your big data problem might actually be a small data problem in disguise. While the complete data might be big, often the data needed to answer a specific question is small. You might be able to find a subset, subsample, or summary that fits in memory and still allows you to answer the question that you’re interested in. The challenge here is finding the right small data, which often requires a lot of iteration." (Grolemund and Wickham, 2019)

---
# So what should we do to handle big data
- First, need to determine if our problem can't be handled as a multiple small data problem. 

- If not, we might want to move into discussing relational databases and postgresql

---
# PostgreSQL?

--
&gt; PostgreSQL is a powerful, open source object-relational database system that uses and extends the SQL language combined with many features that safely store and scale the most complicated data workload (https://www.postgresql.org/about/)

--

- With Postgres, we can solve a lot of problems arising from larger datasets.


---
# Our Task:
- To use PostgreSQL, let's look at the NYC Yellow Taxi data

--
   - Specifically, we will be looking at the 2018 Yellow Taxi data 
    - Has about 112 million rows so will kill most R sessions

---
# To start: creating the database
- We need to create a relational database to start. Thus, we will need to use postgres.



```sql
createdb nyc_yellow_taxi
psql nyc_yellow_taxi
```
---
# Creating the table 

```sql
CREATE TABLE nyc_yellow_2018(
    VendorID varchar(100),
    tpep_pickup_datetime date,
    tpep_dropoff_datetime date,
    passenger_count integer,
    trip_distance float(8),
    RatecodeID varchar(100),
    store_and_fwd_flag varchar(100),
    PULocationID varchar(100),
    DOLocationID varchar(100),
    payment_type varchar(10),
    fare_amount float(8),
    extra float(8),
    mta_tax float(8),
    tip_amount float(8),
    tolls_amount float(8),
    improvement_surcharge float(8),
    total_amount float(8)
);
COPY nyc_yellow_2018
FROM '/home/seabass/2018_Yellow_Taxi_Trip_Data.csv' CSV HEADER;
GRANT ALL PRIVILEGES ON nyc_yellow_2018 TO seabass;
```

--- 
# Integrating R and PostgreSQL
- Now that we have the database and table set up, we can access it through R using DBI

```r
library(DBI)
con &lt;- dbConnect(RPostgres::Postgres(),dbname = "nyc_yellow_taxi") #connect to the database
dbListTables(con)
```

```
## [1] "nyc_yellow_2018"
```
- The above command should show that there is one table called nyc_yellow_2018 available.

---
# Reading the data
- Using either DBI or dplyr, we can bring the tables to manipulate in R as follows:

```r
library(tidyverse)
nyc_yellow_2018 &lt;- tbl(con,"nyc_yellow_2018")
nyc_yellow_2018
```

```
## # Source:   table&lt;nyc_yellow_2018&gt; [?? x 17]
## # Database: postgres [seabass@/var/run/postgresql:5432/nyc_yellow_taxi]
##    vendorid tpep_pickup_dat… tpep_dropoff_da… passenger_count trip_distance
##    &lt;chr&gt;    &lt;date&gt;           &lt;date&gt;                     &lt;int&gt;         &lt;dbl&gt;
##  1 1        2018-11-16       2018-11-16                     3          0.8 
##  2 2        2018-11-16       2018-11-16                     5          3.9 
##  3 1        2018-11-16       2018-11-16                     1          1.1 
##  4 1        2018-11-16       2018-11-16                     2          1.4 
##  5 1        2018-11-16       2018-11-16                     1          1.9 
##  6 2        2018-11-16       2018-11-16                     1          6.48
##  7 2        2018-11-16       2018-11-16                     1          1.88
##  8 2        2018-11-16       2018-11-16                     1          1.24
##  9 2        2018-11-16       2018-11-16                     1          2.25
## 10 2        2018-11-16       2018-11-16                     1          0.42
## # … with more rows, and 12 more variables: ratecodeid &lt;chr&gt;,
## #   store_and_fwd_flag &lt;chr&gt;, pulocationid &lt;chr&gt;, dolocationid &lt;chr&gt;,
## #   payment_type &lt;chr&gt;, fare_amount &lt;dbl&gt;, extra &lt;dbl&gt;, mta_tax &lt;dbl&gt;,
## #   tip_amount &lt;dbl&gt;, tolls_amount &lt;dbl&gt;, improvement_surcharge &lt;dbl&gt;,
## #   total_amount &lt;dbl&gt;
```

---
# Wielding the power of the tidyverse
- One of the great benefits of using the tidyverse is that most of dplyr operates with a SQL backend
- In other words, rather than having to learn SQL like an expert (you should build up familiarity with SQL), you can use many dplyr verbs. for example:

```r
nyc_yellow_2018 %&gt;% 
  select(fare_amount)
```

```
## # Source:   lazy query [?? x 1]
## # Database: postgres [seabass@/var/run/postgresql:5432/nyc_yellow_taxi]
##    fare_amount
##          &lt;dbl&gt;
##  1         9  
##  2        16.5
##  3         8.5
##  4         8  
##  5        11  
##  6        23.5
##  7         8  
##  8         6.5
##  9        10  
## 10         4  
## # … with more rows
```

---
# Lazy Queries and lazy evaluation?
- I mentioned that dplyr and dblyr translate R into sql so any guesses into what lazy evaluation would look like?

--

  - It indicates that R doesn't bring the data until it is asked to. 
  - Dplyr doesn't do any work until the last possible moment by sending everything to the database

--

- So let's look at the underlying SQL query

```r
nyc_yellow_2018 %&gt;% 
  select(fare_amount) %&gt;% 
  show_query()
```

```
## &lt;SQL&gt;
## SELECT "fare_amount"
## FROM "nyc_yellow_2018"
```

- The underlying SQL is what is ultimately sent to our database which queries the table.

---
# What we can't do
- Note, the data that we have pulled in isn't really an R dataframe. See the following.


```r
str(nyc_yellow_2018)
```

```
## List of 2
##  $ src:List of 2
##   ..$ con  :Formal class 'PqConnection' [package "RPostgres"] with 3 slots
##   .. .. ..@ ptr     :&lt;externalptr&gt; 
##   .. .. ..@ bigint  : chr "integer64"
##   .. .. ..@ typnames:'data.frame':	378 obs. of  2 variables:
##   .. .. .. ..$ oid    : int [1:378] 16 17 18 19 20 21 22 23 24 25 ...
##   .. .. .. ..$ typname: chr [1:378] "bool" "bytea" "char" "name" ...
##   ..$ disco: NULL
##   ..- attr(*, "class")= chr [1:4] "src_PqConnection" "src_dbi" "src_sql" "src"
##  $ ops:List of 2
##   ..$ x   : 'ident' chr "nyc_yellow_2018"
##   ..$ vars: chr [1:17] "vendorid" "tpep_pickup_datetime" "tpep_dropoff_datetime" "passenger_count" ...
##   ..- attr(*, "class")= chr [1:3] "op_base_remote" "op_base" "op"
##  - attr(*, "class")= chr [1:5] "tbl_PqConnection" "tbl_dbi" "tbl_sql" "tbl_lazy" ...
```

- Thus, we can't use some regular R functions. For example try using brackets

---
# Exercise:
- Given that we've successfully managed to "read" the data into R, how would we go about finding the following?

 - find the mean, median, maximum, minimum and standard deviation in fare_amount column.
 - find the number of missing observations in the fare_amount column.
 - find the counts of the payment_type column and their respective proportions.

---
--- 
# Solutions

- To find the descriptives, we're going to have to use summarize from dplyr

```r
nyc_yellow_2018 %&gt;% 
  summarise(fare_amount_mean = mean(fare_amount,na.rm = T),
            fare_amount_median = median(fare_amount),
            fare_amount_sd = sd(fare_amount,na.rm = T),
            fare_amount_max = max(fare_amount,na.rm = T),
            fare_amount_min = min(fare_amount,na.rm = T))
```

```
## # Source:   lazy query [?? x 5]
## # Database: postgres [seabass@/var/run/postgresql:5432/nyc_yellow_taxi]
##   fare_amount_mean fare_amount_med… fare_amount_sd fare_amount_max
##              &lt;dbl&gt;            &lt;dbl&gt;          &lt;dbl&gt;           &lt;dbl&gt;
## 1             13.0              9.5           147.         907070.
## # … with 1 more variable: fare_amount_min &lt;dbl&gt;
```

- Never underestimate the power of descriptive statistics as shown above. We would miss some things if we didn't run this

---
# Solutions continued


```r
nyc_yellow_2018 %&gt;% 
  summarise(missing_fare_amount = is.na(fare_amount)) %&gt;% 
  count(missing_fare_amount)
```

```
## # Source:   lazy query [?? x 2]
## # Database: postgres [seabass@/var/run/postgresql:5432/nyc_yellow_taxi]
##   missing_fare_amount n        
##   &lt;lgl&gt;               &lt;int64&gt;  
## 1 FALSE               112234626
```
- From the above, we can see that there are no missing values in fare_amount 

---
# Solutions even further

- finally!

```r
nyc_yellow_2018 %&gt;% 
  count(payment_type) %&gt;% 
  mutate(prop = round(n/sum(n),2))
```

```
## Warning: Missing values are always removed in SQL.
## Use `SUM(x, na.rm = TRUE)` to silence this warning
## This warning is displayed only once per session.
```

```
## # Source:   lazy query [?? x 3]
## # Database: postgres [seabass@/var/run/postgresql:5432/nyc_yellow_taxi]
##   payment_type n         prop
##   &lt;chr&gt;        &lt;int64&gt;  &lt;dbl&gt;
## 1 1            77928307  0.69
## 2 2            33556849  0.3 
## 3 3              582599  0.01
## 4 4              166868  0   
## 5 5                   3  0
```
- This is pretty immensely helpful. If only we knew what those payment_types were...

---
# Visualizations a la grande data

- I like visualizing stuff and would be very, very sad if big data would kill my ability to visualize with tools like ggplot.
  - So does it?

--
.center2[
![](http://giphygifs.s3.amazonaws.com/media/TPl5N4Ci49ZQY/giphy.gif)
]

---
# Let's make some plots!
- Thankfully, there is a way to build plots using DBplot!

.pull-left[

```r
library(dbplot)
nyc_yellow_2018 %&gt;% 
  db_compute_bins(fare_amount) %&gt;% 
  mutate(count = as.numeric(count)) %&gt;% # done to coerce int64 to something ggplot can understand
  ggplot()+
  geom_col(aes(fare_amount,count))+
  theme_minimal()+
  labs(title = "fare amount for nyc yellow taxi 2018",
       x = "fare amount")
```
]
.pull-right[
![](r-postgresql_presentation_files/figure-html/visual-out-1.png)&lt;!-- --&gt;
]

---
# Intermediate data wrangling

- We've noticed that there are some problems with the data in fare amount (chiefly, there seems to be a massive outlier and a large negative number).

- Let's look at the values where the fare values are negative.

```r
under_zero &lt;- nyc_yellow_2018 %&gt;% 
  filter(fare_amount &lt; 0) %&gt;% 
  summarise(count = n()) %&gt;% 
  collect
```

- from the above, we observe 73,049 cases have a value underneath 0 for fare_amount

---
# Which were zeros?

- the values less than 0 are presented as follows:


```r
nyc_yellow_2018 %&gt;% 
  filter(fare_amount &lt; 0 ) %&gt;% 
  distinct(fare_amount) %&gt;% 
  arrange(fare_amount)
```

```
## # Source:     lazy query [?? x 1]
## # Database:   postgres [seabass@/var/run/postgresql:5432/nyc_yellow_taxi]
## # Ordered by: fare_amount
##    fare_amount
##          &lt;dbl&gt;
##  1       -800 
##  2       -498 
##  3       -485 
##  4       -475 
##  5       -468 
##  6       -465 
##  7       -463 
##  8       -460 
##  9       -453.
## 10       -450 
## # … with more rows
```

---
# What should we do? 
- There are two options for dealing with data that should be non-negative
  - replace with zero
  - replace with NA
- If we want to do the first, we can manipulate the data as follows


```r
nyc_yellow_2018 %&gt;% 
  mutate(fare_amount = if_else(fare_amount &lt; 0,0,fare_amount)) 
```

```
## # Source:   lazy query [?? x 17]
## # Database: postgres [seabass@/var/run/postgresql:5432/nyc_yellow_taxi]
##    vendorid tpep_pickup_dat… tpep_dropoff_da… passenger_count trip_distance
##    &lt;chr&gt;    &lt;date&gt;           &lt;date&gt;                     &lt;int&gt;         &lt;dbl&gt;
##  1 1        2018-11-16       2018-11-16                     3          0.8 
##  2 2        2018-11-16       2018-11-16                     5          3.9 
##  3 1        2018-11-16       2018-11-16                     1          1.1 
##  4 1        2018-11-16       2018-11-16                     2          1.4 
##  5 1        2018-11-16       2018-11-16                     1          1.9 
##  6 2        2018-11-16       2018-11-16                     1          6.48
##  7 2        2018-11-16       2018-11-16                     1          1.88
##  8 2        2018-11-16       2018-11-16                     1          1.24
##  9 2        2018-11-16       2018-11-16                     1          2.25
## 10 2        2018-11-16       2018-11-16                     1          0.42
## # … with more rows, and 12 more variables: ratecodeid &lt;chr&gt;,
## #   store_and_fwd_flag &lt;chr&gt;, pulocationid &lt;chr&gt;, dolocationid &lt;chr&gt;,
## #   payment_type &lt;chr&gt;, fare_amount &lt;dbl&gt;, extra &lt;dbl&gt;, mta_tax &lt;dbl&gt;,
## #   tip_amount &lt;dbl&gt;, tolls_amount &lt;dbl&gt;, improvement_surcharge &lt;dbl&gt;,
## #   total_amount &lt;dbl&gt;
```

---
# Some intermediate dplyr tricks
- let's say we wanted to find the mean for passenger count and trip distance at the same time. How would we go about doing that?
  - First thought would be to use summarize


```r
nyc_yellow_2018 %&gt;% 
  summarise(trip_distance_mean = mean(trip_distance))
```

```
## # Source:   lazy query [?? x 1]
## # Database: postgres [seabass@/var/run/postgresql:5432/nyc_yellow_taxi]
##   trip_distance_mean
##                &lt;dbl&gt;
## 1               2.93
```

```r
nyc_yellow_2018 %&gt;% 
  summarise(passenger_count_mean = mean(passenger_count))
```

```
## # Source:   lazy query [?? x 1]
## # Database: postgres [seabass@/var/run/postgresql:5432/nyc_yellow_taxi]
##   passenger_count_mean
##                  &lt;dbl&gt;
## 1                 1.60
```

---
# Scoped dplyr verbs in postgres

- We can use scoped dplyr verbs to greatly speed things up. In the past example, we could use summarize_at as follows


```r
nyc_yellow_2018 %&gt;% 
  summarise_at(vars(c("passenger_count","trip_distance")),mean)
```

```
## # Source:   lazy query [?? x 2]
## # Database: postgres [seabass@/var/run/postgresql:5432/nyc_yellow_taxi]
##   passenger_count trip_distance
##             &lt;dbl&gt;         &lt;dbl&gt;
## 1            1.60          2.93
```

- While the advantages of this aren't immediately apparent, we can start seeing it if I were to ask you to find the mean of every numeric column in the data

---
# More scoping
- Scoped verbs are valuable features and can speed a lot of processes up. Here's a good example


```r
nyc_yellow_2018 %&gt;% 
  summarise_if(is.numeric,mean)
```

```
## Applying predicate on the first 100 rows
```

```
## # Source:   lazy query [?? x 9]
## # Database: postgres [seabass@/var/run/postgresql:5432/nyc_yellow_taxi]
##   passenger_count trip_distance fare_amount extra mta_tax tip_amount
##             &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;
## 1            1.60          2.93        13.0 0.331   0.497       1.87
## # … with 3 more variables: tolls_amount &lt;dbl&gt;,
## #   improvement_surcharge &lt;dbl&gt;, total_amount &lt;dbl&gt;
```

- We've reduced what would have been a large chunk of code to about 2 lines (kind of).

---
# Using SQL if needed
- There may be times when we need to bring out the SQL
- For example, if we wanted to get the number of times each payment type was used as we did previously, we could do the following


```r
dbGetQuery(con,'SELECT COUNT(*) FROM nyc_yellow_2018 GROUP BY payment_type')
```

```
##      count
## 1 77928307
## 2 33556849
## 3   582599
## 4   166868
## 5        3
```

---
# Counting missing values in all columns in one go
- I've delayed this enough, how can we get the missing info in one go?


```r
nyc_yellow_2018 %&gt;% 
  summarise_all(is.na) %&gt;% 
  mutate_all(~if_else(. == TRUE,1,0)) %&gt;% 
  summarise_all(sum)
```

```
## Warning: Missing values are always removed in SQL.
## Use `SUM(x, na.rm = TRUE)` to silence this warning
## This warning is displayed only once per session.
```

```
## # Source:   lazy query [?? x 17]
## # Database: postgres [seabass@/var/run/postgresql:5432/nyc_yellow_taxi]
##   vendorid tpep_pickup_dat… tpep_dropoff_da… passenger_count trip_distance
##      &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;           &lt;dbl&gt;         &lt;dbl&gt;
## 1        0                0                0               0             0
## # … with 12 more variables: ratecodeid &lt;dbl&gt;, store_and_fwd_flag &lt;dbl&gt;,
## #   pulocationid &lt;dbl&gt;, dolocationid &lt;dbl&gt;, payment_type &lt;dbl&gt;,
## #   fare_amount &lt;dbl&gt;, extra &lt;dbl&gt;, mta_tax &lt;dbl&gt;, tip_amount &lt;dbl&gt;,
## #   tolls_amount &lt;dbl&gt;, improvement_surcharge &lt;dbl&gt;, total_amount &lt;dbl&gt;
```

- The power of scoping right here.

---
# Modelling!
- We can do some pretty rough modelling. Let's try a linear regression!


```r
library(modeldb)
nyc_yellow_2018 %&gt;% 
  select(trip_distance,passenger_count,fare_amount) %&gt;% 
  linear_regression_db(y_var = fare_amount,sample_size = 10000000)
```

```
## # A tibble: 1 x 3
##   `(Intercept)` trip_distance passenger_count
##           &lt;dbl&gt;         &lt;dbl&gt;           &lt;dbl&gt;
## 1          12.5         0.127          0.0772
```

- Whether these results make sense or not are the subject of more investigation

---
# More advanced modelling
- We can use more advanced modelling using tidypredict, parsnip, and other packages from the tidymodels ecosystem. 


```r
library(tidymodels)
yellow_sample &lt;- dbGetQuery(con,'SELECT "fare_amount", "vendorid", "tip_amount","trip_distance","tolls_amount" FROM nyc_yellow_2018 ORDER BY RANDOM() LIMIT 10000') %&gt;% 
  as_tibble()

lin_reg &lt;- linear_reg()
rand_model &lt;- lin_reg %&gt;% 
  set_engine("lm") %&gt;% 
  fit(tip_amount ~ . ,data = yellow_sample)
yellow_sample %&gt;% 
  bind_cols(predict(rand_model,yellow_sample)) %&gt;% 
  metrics(truth = tip_amount,estimate = .pred)
```

```
## # A tibble: 3 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard       1.89 
## 2 rsq     standard       0.414
## 3 mae     standard       1.30
```

---
--- 
# Testing our model on the database

- We can evaluate our model's predictions as follows

```r
nyc_yellow_2018 %&gt;% 
  tidypredict::tidypredict_to_column(rand_model) %&gt;% 
  select(tip_amount,fit)
```

```
## # Source:   lazy query [?? x 2]
## # Database: postgres [seabass@/var/run/postgresql:5432/nyc_yellow_taxi]
##    tip_amount   fit
##         &lt;dbl&gt; &lt;dbl&gt;
##  1       0    1.29 
##  2       0    2.17 
##  3       0    1.27 
##  4       1    1.25 
##  5       0    1.56 
##  6       0    3.01 
##  7       0    1.25 
##  8       1.56 1.06 
##  9       1    1.46 
## 10       0    0.770
## # … with more rows
```
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
